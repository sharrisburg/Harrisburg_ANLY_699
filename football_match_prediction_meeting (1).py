# -*- coding: utf-8 -*-
"""Football Match Prediction_meeting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A1mc5o0dYOSU_EoP0q06CxekQGol5b66
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from datetime import datetime as dt
import itertools

# %matplotlib inline


# Set up a general style for the plots
plt.style.use('ggplot')

from google.colab import drive
drive.mount('/content/drive')

# Read data from the CSV into a dataframe

folder='/content/drive/MyDrive/Colab Notebooks/Football Match Prediction/'
data = pd.read_csv(folder + 'final_dataset.csv')

# Display the first few rows to understand the structure of the data
print(data.head())

data.columns

# Clean the dataset by dropping unnecessary columns and handling missing data
data_cleaned = data.drop(columns=['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam'])
data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce').fillna(0)

# Plot correlation matrix to identify which factors are correlated with match results (FTR)
plt.figure(figsize=(12, 8))
correlation_matrix = data_cleaned.corr()

# Plotting the heatmap for correlations
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of Match Factors')
plt.show()

# Plot correlation matrix to identify which factors are correlated with match results (FTR)
plt.figure(figsize=(12, 8))
correlation_matrix = data_cleaned.corr()
# Plotting the heatmap for correlations
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of Match Factors')
plt.show()

# Analyze which factors correlate most with Full-Time Result (FTR)
# Plot pairplot for key factors that have high correlation with 'FTR' (Home Goals, Away Goals, HTGD, ATGD, DiffPts)
important_columns = ['FTHG', 'FTAG', 'HTGD', 'ATGD', 'DiffPts', 'DiffFormPts']
sns.pairplot(data_cleaned[important_columns])
plt.suptitle('Key Match Factor Relationships', y=1.02)
plt.show()

# Visualize the distribution of Full-Time Home Goals (FTHG) and Away Goals (FTAG) based on the result (FTR)
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='FTHG', hue='FTR', multiple='stack', palette='Set2', bins=5)
plt.title('Distribution of Full-Time Home Goals by Match Result')
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='FTAG', hue='FTR', multiple='stack', palette='Set1', bins=5)
plt.title('Distribution of Full-Time Away Goals by Match Result')
plt.show()

# Bar plot for average goal differences (HTGD, ATGD) based on result
plt.figure(figsize=(10, 6))
sns.barplot(data=data, x='FTR', y='HTGD', palette='viridis')
plt.title('Average Home Goal Difference by Match Result')
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(data=data, x='FTR', y='ATGD', palette='magma')
plt.title('Average Away Goal Difference by Match Result')
plt.show()

# Now for ranking the top factors based on their correlation with match result (FTR)
# I'll use the FTHG (Full-time Home Goals) and FTAG (Full-time Away Goals) to create a binary win condition
data_cleaned['FTR_binary'] = data['FTR'].apply(lambda x: 1 if x == 'H' else 0)

# Ranking factors by their absolute correlation with FTR
factor_correlation = data_cleaned.corr()['FTR_binary'].abs().sort_values(ascending=False)

# Get the top 10 factors most correlated with home wins
top_factors = factor_correlation.head(10)

# Visualize top 10 factors contributing to home win
plt.figure(figsize=(10, 6))
sns.barplot(x=top_factors.index, y=top_factors.values, palette='Blues_d')
plt.title('Top 10 Factors Contributing to Home Wins (Correlation with FTR)')
plt.ylabel('Correlation')
plt.xticks(rotation=45)
plt.show()

# Now let's visualize the trend of home wins and away wins over time
# Extracting year from the 'Date' column for trend analysis
data['Year'] = pd.to_datetime(data['Date'], errors='coerce').dt.year

# Calculate win percentages for home and away over the years
home_wins_per_year = data[data['FTR'] == 'H'].groupby('Year').size() / data.groupby('Year').size() * 100
away_wins_per_year = data[data['FTR'] == 'A'].groupby('Year').size() / data.groupby('Year').size() * 100

# Plot the trend of home win and away win percentages
plt.figure(figsize=(12, 6))
home_wins_per_year.plot(label='Home Win Percentage', marker='o', linestyle='-', color='blue')
away_wins_per_year.plot(label='Away Win Percentage', marker='o', linestyle='-', color='red')
plt.title('Trend of Home and Away Win Percentages Over Time')
plt.xlabel('Year')
plt.ylabel('Win Percentage')
plt.legend()
plt.grid(True)
plt.show()

# Additional trend analysis
# Calculate goal trends (average home and away goals per year)
avg_home_goals_per_year = data.groupby('Year')['FTHG'].mean()
avg_away_goals_per_year = data.groupby('Year')['FTAG'].mean()

# Plot the trends of average home and away goals per year
plt.figure(figsize=(12, 6))
avg_home_goals_per_year.plot(label='Average Home Goals per Year', marker='o', linestyle='-', color='green')
avg_away_goals_per_year.plot(label='Average Away Goals per Year', marker='o', linestyle='-', color='orange')
plt.title('Trend of Average Home and Away Goals Over Time')
plt.xlabel('Year')
plt.ylabel('Average Goals')
plt.legend()
plt.grid(True)
plt.show()

pip install shap

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import shap
import matplotlib.pyplot as plt

# Convert the target variable FTR (Full-Time Result) into numerical labels
label_encoder = LabelEncoder()
data_cleaned['FTR'] = label_encoder.fit_transform(data['FTR'])

# Define features (X) and target (y)
X = data_cleaned.drop(columns=['FTR'])  # All columns except FTR
y = data_cleaned['FTR']  # FTR column as target

# Split the dataset into training and testing sets
X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = X_train_full.drop(columns=['FTR_binary', 'FTAG', 'FTHG'])
X_test = X_test_full.drop(columns=['FTR_binary', 'FTAG', 'FTHG'])


# 1) Decision Tree Model
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(X_train, y_train)

# Predict and evaluate Decision Tree
y_pred_dt = decision_tree.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print("Decision Tree Accuracy: ", accuracy_dt)
print("Decision Tree Classification Report:\n", classification_report(y_test, y_pred_dt))
print("Decision Tree Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))

# 2) Random Forest Model
random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest.fit(X_train, y_train)

# Predict and evaluate Random Forest
y_pred_rf = random_forest.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy: ", accuracy_rf)
print("Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Random Forest Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

# 3) XGBoost Model
xgboost = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')
xgboost.fit(X_train, y_train)

# Predict and evaluate XGBoost
y_pred_xgb = xgboost.predict(X_test)
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
print("XGBoost Accuracy: ", accuracy_xgb)
print("XGBoost Classification Report:\n", classification_report(y_test, y_pred_xgb))
print("XGBoost Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))

# ----- SHAP Analysis -----
# Create SHAP explainers for each model
explainer_dt = shap.TreeExplainer(decision_tree)
explainer_rf = shap.TreeExplainer(random_forest)
explainer_xgb = shap.TreeExplainer(xgboost)

# Compute SHAP values for the test set
# For multiclass classification, shap_values is a list of arrays (one for each class)
shap_values_dt = explainer_dt.shap_values(X_test)
shap_values_rf = explainer_rf.shap_values(X_test)
shap_values_xgb = explainer_xgb.shap_values(X_test)

# SHAP summary for Class 0 (e.g., Home Win)
print("SHAP Summary for Decision Tree")
shap.summary_plot(shap_values_dt[:, :, 0], X_test, plot_type="bar", show=False)
plt.title('Decision Tree - Class 0')
plt.show()
# SHAP summary for Class 1 (e.g., Away Win)
shap.summary_plot(shap_values_dt[:, :, 1], X_test, plot_type="bar", show=False)
plt.title('Decision Tree - Class 1')
plt.show()

# ----- SHAP Summary Plots for Random Forest -----
# For Random Forest (2 classes, shap_values_rf also has 2 sets of SHAP values)
print("SHAP Summary for Random Forest")

# SHAP summary for Class 0 (e.g., Home Win)
shap.summary_plot(shap_values_rf[:, :, 0], X_test, plot_type="bar", show=False)
plt.title('Random Forest - Class 0')
plt.show()
# SHAP summary for Class 1 (e.g., Away Win)
shap.summary_plot(shap_values_rf[:, :, 1], X_test, plot_type="bar", show=False)
plt.title('Random Forest - Class 1')
plt.show()

# ----- SHAP Summary Plot for XGBoost -----
# For XGBoost, shap_values_xgb has 1 set of SHAP values
print("SHAP Summary for XGBoost")

# SHAP summary for XGBoost (Single set of SHAP values)
shap.summary_plot(shap_values_xgb, X_test, plot_type="bar", show=False)
plt.title('XGBoost')
plt.show()

import numpy as np
import pandas as pd

# ----- SHAP Analysis for Decision Tree -----
# Get the absolute SHAP values for Class 0 and Class 1 for Decision Tree
shap_values_dt_class_0 = np.abs(shap_values_dt[:, :, 0])
shap_values_dt_class_1 = np.abs(shap_values_dt[:, :, 1])

# Calculate the mean absolute SHAP values for each feature
mean_shap_dt_class_0 = pd.DataFrame(shap_values_dt_class_0, columns=X_test.columns).mean()
mean_shap_dt_class_1 = pd.DataFrame(shap_values_dt_class_1, columns=X_test.columns).mean()

# Analyze the top 5 features for Decision Tree - Class 0 (Home Win)
print("Top 5 Features for Decision Tree (Class 0 - Home Win):")
print(mean_shap_dt_class_0.sort_values(ascending=False).head(5))

# Analyze the top 5 features for Decision Tree - Class 1 (Away Win)
print("Top 5 Features for Decision Tree (Class 1 - Away Win):")
print(mean_shap_dt_class_1.sort_values(ascending=False).head(5))

# ----- SHAP Analysis for Random Forest -----
# Get the absolute SHAP values for Class 0 and Class 1 for Random Forest
shap_values_rf_class_0 = np.abs(shap_values_rf[:, :, 0])
shap_values_rf_class_1 = np.abs(shap_values_rf[:, :, 1])

# Calculate the mean absolute SHAP values for each feature
mean_shap_rf_class_0 = pd.DataFrame(shap_values_rf_class_0, columns=X_test.columns).mean()
mean_shap_rf_class_1 = pd.DataFrame(shap_values_rf_class_1, columns=X_test.columns).mean()

# Analyze the top 5 features for Random Forest - Class 0 (Home Win)
print("Top 5 Features for Random Forest (Class 0 - Home Win):")
print(mean_shap_rf_class_0.sort_values(ascending=False).head(5))

# Analyze the top 5 features for Random Forest - Class 1 (Away Win)
print("Top 5 Features for Random Forest (Class 1 - Away Win):")
print(mean_shap_rf_class_1.sort_values(ascending=False).head(5))

# ----- SHAP Analysis for XGBoost -----
# Get the absolute SHAP values for XGBoost (since it has only one set of values)
shap_values_xgb_abs = np.abs(shap_values_xgb)

# Calculate the mean absolute SHAP values for each feature
mean_shap_xgb = pd.DataFrame(shap_values_xgb_abs, columns=X_test.columns).mean()

# Analyze the top 5 features for XGBoost
print("Top 5 Features for XGBoost:")
print(mean_shap_xgb.sort_values(ascending=False).head(5))

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, classification_report

# 1. Fine-tuning Decision Tree
dt_params = {
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 5, 10],
    'criterion': ['gini', 'entropy']
}

dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy')
dt_grid_search.fit(X_train, y_train)
best_dt = dt_grid_search.best_estimator_

# Evaluate Decision Tree
y_pred_dt = best_dt.predict(X_test)
print("Tuned Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print("Tuned Decision Tree Classification Report:\n", classification_report(y_test, y_pred_dt))

# 2. Fine-tuning Random Forest
rf_params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5],
    'bootstrap': [True, False]
}

rf_random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_params, n_iter=20, cv=5, scoring='accuracy', random_state=42)
rf_random_search.fit(X_train, y_train)
best_rf = rf_random_search.best_estimator_

# Evaluate Random Forest
y_pred_rf = best_rf.predict(X_test)
print("Tuned Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Tuned Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))

# 3. Fine-tuning XGBoost
xgb_params = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 6, 10, 15],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3]
}

xgb_random_search = RandomizedSearchCV(
    XGBClassifier(random_state=42, eval_metric='mlogloss'),
    xgb_params,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    random_state=42
)
xgb_random_search.fit(X_train, y_train)
best_xgb = xgb_random_search.best_estimator_

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Evaluate the fine-tuned Decision Tree model
y_pred_dt = best_dt.predict(X_test)
print("Tuned Decision Tree Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("Classification Report:\n", classification_report(y_test, y_pred_dt))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))

# Evaluate the fine-tuned Random Forest model
y_pred_rf = best_rf.predict(X_test)
print("\nTuned Random Forest Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

# Evaluate the fine-tuned XGBoost model
y_pred_xgb = best_xgb.predict(X_test)
print("\nTuned XGBoost Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Classification Report:\n", classification_report(y_test, y_pred_xgb))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))

import shap
import matplotlib.pyplot as plt

# Create SHAP explainers for each fine-tuned model
explainer_dt = shap.TreeExplainer(best_dt)     # Tuned Decision Tree
explainer_rf = shap.TreeExplainer(best_rf)     # Tuned Random Forest
explainer_xgb = shap.TreeExplainer(best_xgb)   # Tuned XGBoost

# Compute SHAP values for the test set
shap_values_dt = explainer_dt.shap_values(X_test)
shap_values_rf = explainer_rf.shap_values(X_test)
shap_values_xgb = explainer_xgb.shap_values(X_test)

# ----- SHAP Summary Plot for Decision Tree -----
print("SHAP Summary for Tuned Decision Tree")
shap.summary_plot(shap_values_dt, X_test, plot_type="bar")
plt.title('SHAP Summary Plot for Tuned Decision Tree')
plt.show()

# ----- SHAP Summary Plot for Random Forest -----
print("SHAP Summary for Tuned Random Forest")
shap.summary_plot(shap_values_rf, X_test, plot_type="bar")
plt.title('SHAP Summary Plot for Tuned Random Forest')
plt.show()

# ----- SHAP Summary Plot for XGBoost -----
print("SHAP Summary for Tuned XGBoost")
shap.summary_plot(shap_values_xgb, X_test, plot_type="bar")
plt.title('SHAP Summary Plot for Tuned XGBoost')
plt.show()

# Decision Tree - Average SHAP values across classes
shap_values_dt_avg = np.mean(np.abs(shap_values_dt), axis=2)
mean_shap_dt = pd.DataFrame(shap_values_dt_avg, columns=X_test.columns).mean()
top_features_dt = mean_shap_dt.sort_values(ascending=False).head(5)
print("Top 5 Features for Decision Tree (Average SHAP values across classes):")
print(top_features_dt)

# Random Forest - Average SHAP values across classes
shap_values_rf_avg = np.mean(np.abs(shap_values_rf), axis=2)
mean_shap_rf = pd.DataFrame(shap_values_rf_avg, columns=X_test.columns).mean()
top_features_rf = mean_shap_rf.sort_values(ascending=False).head(5)
print("\nTop 5 Features for Random Forest (Average SHAP values across classes):")
print(top_features_rf)

# XGBoost - Single class SHAP values (only one class, so no need to average)
shap_values_xgb_abs = np.abs(shap_values_xgb)
mean_shap_xgb = pd.DataFrame(shap_values_xgb_abs, columns=X_test.columns).mean()
top_features_xgb = mean_shap_xgb.sort_values(ascending=False).head(5)
print("\nTop 5 Features for XGBoost (SHAP values):")
print(top_features_xgb)

pip install pytorch-tabnet

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import torch

# Load the dataset

folder='/content/drive/MyDrive/Colab Notebooks/Football Match Prediction/'
data = pd.read_csv(folder + 'final_dataset.csv')


# Preprocessing
# Drop irrelevant columns
data_cleaned = data.drop(columns=['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam'])

# Handle missing values by filling them with 0
data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce').fillna(0)

# Encode the target variable
label_encoder = LabelEncoder()
data_cleaned['FTR'] = label_encoder.fit_transform(data['FTR'])

# Define features (X) and target (y)
X = data_cleaned.drop(columns=['FTR']).values
y = data_cleaned['FTR'].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Convert the data into float32 for TabNet
X_train = X_train.astype(np.float32)
X_test = X_test.astype(np.float32)

# Initialize the TabNet classifier
tabnet_clf = TabNetClassifier(
    n_d=8, n_a=8,
    n_steps=3,
    gamma=1.3,
    n_independent=2, n_shared=2,
    lambda_sparse=1e-3,
    optimizer_fn=torch.optim.Adam,
    optimizer_params=dict(lr=2e-2),
    mask_type='sparsemax',
    scheduler_params={"step_size":10, "gamma":0.9},
    scheduler_fn=torch.optim.lr_scheduler.StepLR,
    verbose=10
)

# Train the TabNet model
tabnet_clf.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_test, y_test)],
    eval_name=['train', 'test'],
    eval_metric=['accuracy'],
    max_epochs=50,
    patience=10,
    batch_size=1024,
    virtual_batch_size=128,
    num_workers=0,
    drop_last=False
)

# Make predictions
y_pred = tabnet_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print("TabNet Accuracy:", accuracy)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Extract feature importance
feature_importances = tabnet_clf.feature_importances_
feature_names = data_cleaned.drop(columns=['FTR']).columns
feature_importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

print("\nTop 5 Features based on TabNet:")
print(feature_importance_df.head(5))

# Visualize feature importance
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.title('TabNet Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Features')
plt.gca().invert_yaxis()
plt.show()

pip install optuna pytorch-tabnet

import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
import torch
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load the dataset
folder='/content/drive/MyDrive/Colab Notebooks/Football Match Prediction/'
data = pd.read_csv(folder + 'final_dataset.csv')


# Preprocessing
data_cleaned = data.drop(columns=['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam'])
data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce').fillna(0)

label_encoder = LabelEncoder()
data_cleaned['FTR'] = label_encoder.fit_transform(data_cleaned['FTR'])
X = data_cleaned.drop(columns=['FTR']).values
y = data_cleaned['FTR'].values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Convert to float32 for TabNet
X_train = X_train.astype(np.float32)
X_test = X_test.astype(np.float32)


### 1. Fine-tuning Decision Tree ###
def objective_dt(trial):
    params = {
        'max_depth': trial.suggest_int('max_depth', 2, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),
        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),
    }
    model = DecisionTreeClassifier(**params, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


### 2. Fine-tuning Random Forest ###
def objective_rf(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300),
        'max_depth': trial.suggest_int('max_depth', 5, 30),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),
        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),
    }
    model = RandomForestClassifier(**params, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


### 3. Fine-tuning XGBoost ###
def objective_xgb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 0.5),
    }
    model = XGBClassifier(**params, random_state=42, eval_metric='mlogloss')
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


### 4. Fine-tuning TabNet ###
def objective_tabnet(trial):
    params = {
        'n_d': trial.suggest_int('n_d', 8, 64),
        'n_a': trial.suggest_int('n_a', 8, 64),
        'n_steps': trial.suggest_int('n_steps', 3, 10),
        'gamma': trial.suggest_float('gamma', 1.0, 2.0),
        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-5, 1e-1),
        'momentum': trial.suggest_float('momentum', 0.02, 0.4)
    }
    model = TabNetClassifier(**params, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))
    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)


# Optimize each model using Optuna
study_dt = optuna.create_study(direction='maximize')
study_dt.optimize(objective_dt, n_trials=50)

study_rf = optuna.create_study(direction='maximize')
study_rf.optimize(objective_rf, n_trials=50)

study_xgb = optuna.create_study(direction='maximize')
study_xgb.optimize(objective_xgb, n_trials=50)

study_tabnet = optuna.create_study(direction='maximize')
study_tabnet.optimize(objective_tabnet, n_trials=50)

# Print best hyperparameters and accuracy for each model
print("Best Decision Tree Params:", study_dt.best_params)
print("Best Decision Tree Accuracy:", study_dt.best_value)

print("Best Random Forest Params:", study_rf.best_params)
print("Best Random Forest Accuracy:", study_rf.best_value)

print("Best XGBoost Params:", study_xgb.best_params)
print("Best XGBoost Accuracy:", study_xgb.best_value)

print("Best TabNet Params:", study_tabnet.best_params)
print("Best TabNet Accuracy:", study_tabnet.best_value)

import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Extract the best models from Optuna studies
best_dt_model = DecisionTreeClassifier(**study_dt.best_params, random_state=42)
best_rf_model = RandomForestClassifier(**study_rf.best_params, random_state=42)
best_xgb_model = XGBClassifier(**study_xgb.best_params, random_state=42, eval_metric='mlogloss')
best_tabnet_model = TabNetClassifier(**study_tabnet.best_params, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))

# Fit the best models on the training data
best_dt_model.fit(X_train, y_train)
best_rf_model.fit(X_train, y_train)
best_xgb_model.fit(X_train, y_train)
best_tabnet_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)

# SHAP analysis for Decision Tree
explainer_dt = shap.TreeExplainer(best_dt_model)
shap_values_dt = explainer_dt.shap_values(X_test)
shap_values_dt_abs = np.abs(shap_values_dt)
mean_shap_dt = pd.DataFrame(shap_values_dt_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_dt = mean_shap_dt.sort_values(ascending=False).head(5)

# SHAP analysis for Random Forest
explainer_rf = shap.TreeExplainer(best_rf_model)
shap_values_rf = explainer_rf.shap_values(X_test)
shap_values_rf_abs = np.abs(shap_values_rf)
mean_shap_rf = pd.DataFrame(shap_values_rf_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_rf = mean_shap_rf.sort_values(ascending=False).head(5)

# SHAP analysis for XGBoost
explainer_xgb = shap.TreeExplainer(best_xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_test)
shap_values_xgb_abs = np.abs(shap_values_xgb)
mean_shap_xgb = pd.DataFrame(shap_values_xgb_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_xgb = mean_shap_xgb.sort_values(ascending=False).head(5)

# Feature importance for TabNet
feature_importances_tabnet = best_tabnet_model.feature_importances_
mean_shap_tabnet = pd.Series(feature_importances_tabnet, index=data_cleaned.drop(columns=['FTR']).columns)
top_features_tabnet = mean_shap_tabnet.sort_values(ascending=False).head(5)

# Display results in table format
print("\nTop 5 Features and Best Parameters for Each Model:")

# Decision Tree Results
print("\nDecision Tree:")
print("Best Parameters:", study_dt.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_dt)

# Random Forest Results
print("\nRandom Forest:")
print("Best Parameters:", study_rf.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_rf)

# XGBoost Results
print("\nXGBoost:")
print("Best Parameters:", study_xgb.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_xgb)

# TabNet Results
print("\nTabNet:")
print("Best Parameters:", study_tabnet.best_params)
print("Top 5 Features (Feature Importance):")
print(top_features_tabnet)

import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Extract the best models from Optuna studies
best_dt_model = DecisionTreeClassifier(**study_dt.best_params, random_state=42)
best_rf_model = RandomForestClassifier(**study_rf.best_params, random_state=42)
best_xgb_model = XGBClassifier(**study_xgb.best_params, random_state=42, eval_metric='mlogloss')
best_tabnet_model = TabNetClassifier(**study_tabnet.best_params, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))

# Fit the best models on the training data
best_dt_model.fit(X_train, y_train)
best_rf_model.fit(X_train, y_train)
best_xgb_model.fit(X_train, y_train)
best_tabnet_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)

# SHAP analysis for Decision Tree
explainer_dt = shap.TreeExplainer(best_dt_model)
shap_values_dt = explainer_dt.shap_values(X_test)
shap_values_dt_abs = np.abs(shap_values_dt)
mean_shap_dt = pd.DataFrame(shap_values_dt_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_dt = mean_shap_dt.sort_values(ascending=False).head(5)

# SHAP analysis for Random Forest
explainer_rf = shap.TreeExplainer(best_rf_model)
shap_values_rf = explainer_rf.shap_values(X_test)
shap_values_rf_abs = np.abs(shap_values_rf)
mean_shap_rf = pd.DataFrame(shap_values_rf_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_rf = mean_shap_rf.sort_values(ascending=False).head(5)

# SHAP analysis for XGBoost
explainer_xgb = shap.TreeExplainer(best_xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_test)
shap_values_xgb_abs = np.abs(shap_values_xgb)
mean_shap_xgb = pd.DataFrame(shap_values_xgb_abs, columns=data_cleaned.drop(columns=['FTR']).columns).mean()
top_features_xgb = mean_shap_xgb.sort_values(ascending=False).head(5)

# Feature importance for TabNet
feature_importances_tabnet = best_tabnet_model.feature_importances_
mean_shap_tabnet = pd.Series(feature_importances_tabnet, index=data_cleaned.drop(columns=['FTR']).columns)
top_features_tabnet = mean_shap_tabnet.sort_values(ascending=False).head(5)

# Display results in table format
print("\nTop 5 Features and Best Parameters for Each Model:")

# Decision Tree Results
print("\nDecision Tree:")
print("Best Parameters:", study_dt.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_dt)

# Random Forest Results
print("\nRandom Forest:")
print("Best Parameters:", study_rf.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_rf)

# XGBoost Results
print("\nXGBoost:")
print("Best Parameters:", study_xgb.best_params)
print("Top 5 Features (SHAP values):")
print(top_features_xgb)

# TabNet Results
print("\nTabNet:")
print("Best Parameters:", study_tabnet.best_params)
print("Top 5 Features (Feature Importance):")
print(top_features_tabnet)

import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
import torch
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
import shap

# Load and preprocess the dataset
folder='/content/drive/MyDrive/Colab Notebooks/Football Match Prediction/'
data = pd.read_csv(folder + 'final_dataset.csv')
data_cleaned = data.drop(columns=['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam'])
data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce').fillna(0)
label_encoder = LabelEncoder()
data_cleaned['FTR'] = label_encoder.fit_transform(data_cleaned['FTR'])
X = data_cleaned.drop(columns=['FTR']).values
y = data_cleaned['FTR'].values

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)
X = X.astype(np.float32)

# Set seeds to run experiments
random_seeds = [42, 100, 123, 2024, 999]
results = {'Decision Tree': [], 'Random Forest': [], 'XGBoost': [], 'TabNet': []}

def run_experiment_with_seed(model_func, X, y, seed):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)
    return model_func(X_train, X_test, y_train, y_test)

# Define the objective function for each model
def decision_tree_objective(X_train, X_test, y_train, y_test):
    model = DecisionTreeClassifier(max_depth=10, min_samples_split=4, min_samples_leaf=2, criterion='entropy')
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

def random_forest_objective(X_train, X_test, y_train, y_test):
    model = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=6, min_samples_leaf=2, bootstrap=True, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

def xgboost_objective(X_train, X_test, y_train, y_test):
    model = XGBClassifier(n_estimators=300, learning_rate=0.1, max_depth=10, subsample=0.8, colsample_bytree=0.8, gamma=0.2, random_state=42, eval_metric='mlogloss')
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

def tabnet_objective(X_train, X_test, y_train, y_test):
    model = TabNetClassifier(n_d=32, n_a=32, n_steps=5, gamma=1.5, lambda_sparse=0.01, momentum=0.3, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))
    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)
    y_pred = model.predict(X_test)
    return accuracy_score(y_test, y_pred)

# Running experiments for each model and seed
for seed in random_seeds:
    results['Decision Tree'].append(run_experiment_with_seed(decision_tree_objective, X, y, seed))
    results['Random Forest'].append(run_experiment_with_seed(random_forest_objective, X, y, seed))
    results['XGBoost'].append(run_experiment_with_seed(xgboost_objective, X, y, seed))
    results['TabNet'].append(run_experiment_with_seed(tabnet_objective, X, y, seed))

# Calculate the median accuracy for each model
for model_name, accuracies in results.items():
    print(f"\n{model_name} Accuracies: {accuracies}")
    print(f"{model_name} Median Accuracy: {np.median(accuracies):.4f}")

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
import torch

# Define 5 different random seeds
random_seeds = [42, 2023, 7, 99, 1234]

# Initialize lists to store results
results = {
    'Decision Tree': [],
    'Random Forest': [],
    'XGBoost': [],
    'TabNet': []
}

# Define function to train and evaluate models with different random seeds
def evaluate_models(seed):
    print(f"\nRunning models with random seed: {seed}")

    # Decision Tree
    dt_model = DecisionTreeClassifier(**study_dt.best_params, random_state=seed)
    dt_model.fit(X_train, y_train)
    y_pred_dt = dt_model.predict(X_test)
    acc_dt = accuracy_score(y_test, y_pred_dt)
    results['Decision Tree'].append(acc_dt)

    # Random Forest
    rf_model = RandomForestClassifier(**study_rf.best_params, random_state=seed)
    rf_model.fit(X_train, y_train)
    y_pred_rf = rf_model.predict(X_test)
    acc_rf = accuracy_score(y_test, y_pred_rf)
    results['Random Forest'].append(acc_rf)

    # XGBoost
    xgb_model = XGBClassifier(**study_xgb.best_params, random_state=seed, eval_metric='mlogloss')
    xgb_model.fit(X_train, y_train)
    y_pred_xgb = xgb_model.predict(X_test)
    acc_xgb = accuracy_score(y_test, y_pred_xgb)
    results['XGBoost'].append(acc_xgb)

    # TabNet
    tabnet_model = TabNetClassifier(**study_tabnet.best_params, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))
    tabnet_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)
    y_pred_tabnet = tabnet_model.predict(X_test)
    acc_tabnet = accuracy_score(y_test, y_pred_tabnet)
    results['TabNet'].append(acc_tabnet)

# Run the models with 5 different random seeds
for seed in random_seeds:
    evaluate_models(seed)

# Convert results to DataFrame for easier analysis
results_df = pd.DataFrame(results)

# Calculate summary statistics for each model
summary_stats = results_df.describe().transpose()
summary_stats['range'] = summary_stats['max'] - summary_stats['min']

# Display the summary statistics using pandas
print("\nModel Performance with Random Seeds:")
print(summary_stats)

# Optionally, visualize the results using matplotlib
import matplotlib.pyplot as plt

# Plot the performance of each model
results_df.plot(kind='box', figsize=(10, 6), title='Model Accuracy Distribution with Random Seeds')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

import shap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from pytorch_tabnet.tab_model import TabNetClassifier
import torch

# Extract the best models from Optuna studies
best_dt_model = DecisionTreeClassifier(**study_dt.best_params, random_state=42)
best_rf_model = RandomForestClassifier(**study_rf.best_params, random_state=42)
best_xgb_model = XGBClassifier(**study_xgb.best_params, random_state=42, eval_metric='mlogloss')
best_tabnet_model = TabNetClassifier(**study_tabnet.best_params, optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2))

# Fit the best models on the training data
best_dt_model.fit(X_train, y_train)
best_rf_model.fit(X_train, y_train)
best_xgb_model.fit(X_train, y_train)
best_tabnet_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=['accuracy'], patience=10, max_epochs=50)

# Prepare feature names
feature_names = data_cleaned.drop(columns=['FTR']).columns

# ----- SHAP Analysis for Decision Tree -----
explainer_dt = shap.TreeExplainer(best_dt_model)
shap_values_dt = explainer_dt.shap_values(X_test)
mean_shap_dt = pd.DataFrame(np.abs(shap_values_dt).mean(axis=0), index=feature_names, columns=['Importance']).sort_values(by='Importance', ascending=False)

# ----- SHAP Analysis for Random Forest -----
explainer_rf = shap.TreeExplainer(best_rf_model)
shap_values_rf = explainer_rf.shap_values(X_test)
mean_shap_rf = pd.DataFrame(np.abs(shap_values_rf).mean(axis=0), index=feature_names, columns=['Importance']).sort_values(by='Importance', ascending=False)

# ----- SHAP Analysis for XGBoost -----
explainer_xgb = shap.TreeExplainer(best_xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_test)
mean_shap_xgb = pd.DataFrame(np.abs(shap_values_xgb).mean(axis=0), index=feature_names, columns=['Importance']).sort_values(by='Importance', ascending=False)

# ----- Feature Importance for TabNet -----
feature_importances_tabnet = best_tabnet_model.feature_importances_
mean_shap_tabnet = pd.DataFrame(feature_importances_tabnet, index=feature_names, columns=['Importance']).sort_values(by='Importance', ascending=False)

# Display top 5 features for each model
print("\nTop 5 Features from Decision Tree (SHAP values):")
print(mean_shap_dt.head(5))

print("\nTop 5 Features from Random Forest (SHAP values):")
print(mean_shap_rf.head(5))

print("\nTop 5 Features from XGBoost (SHAP values):")
print(mean_shap_xgb.head(5))

print("\nTop 5 Features from TabNet (Feature Importance):")
print(mean_shap_tabnet.head(5))

# ----- Visualization -----
def plot_feature_importance(df, model_name):
    plt.figure(figsize=(10, 6))
    plt.barh(df.index, df['Importance'])
    plt.title(f'Feature Importance - {model_name}')
    plt.xlabel('Importance')
    plt.ylabel('Features')
    plt.gca().invert_yaxis()
    plt.show()

# Plot feature importance for each model
plot_feature_importance(mean_shap_dt.head(10), "Decision Tree")
plot_feature_importance(mean_shap_rf.head(10), "Random Forest")
plot_feature_importance(mean_shap_xgb.head(10), "XGBoost")
plot_feature_importance(mean_shap_tabnet.head(10), "TabNet")

import random
import numpy as np
import pandas as pd
from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
import torch

# Random seed generator
random_seeds = random.sample(range(1, 10000), 5)  # Generate 5 random seeds

# Load the dataset
folder='/content/drive/MyDrive/Colab Notebooks/Football Match Prediction/'
data = pd.read_csv(folder + 'final_dataset.csv')

# Preprocessing
data_cleaned = data.drop(columns=['Unnamed: 0', 'Date', 'HomeTeam', 'AwayTeam'])
data_cleaned = data_cleaned.apply(pd.to_numeric, errors='coerce').fillna(0)

label_encoder = LabelEncoder()
data_cleaned['FTR'] = label_encoder.fit_transform(data_cleaned['FTR'])
X = data_cleaned.drop(columns=['FTR']).values
y = data_cleaned['FTR'].values

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)
X = X.astype(np.float32)  # Convert to float32 for TabNet

# Results storage
results = []
classification_reports = {}

# Define TabNet model hyperparameters (you can fine-tune further if needed)
tabnet_params = {
    'n_d': 32,
    'n_a': 32,
    'n_steps': 5,
    'gamma': 1.5,
    'lambda_sparse': 1e-3,
    'optimizer_fn': torch.optim.Adam,
    'optimizer_params': dict(lr=2e-2),
    'scheduler_params': {"step_size":10, "gamma":0.9},
    'scheduler_fn': torch.optim.lr_scheduler.StepLR,
    'mask_type': "sparsemax",  # sparsemax or entmax
}

# Run the TabNet model with different random seeds
for seed in random_seeds:
    print(f"\nRunning TabNet model with random seed: {seed}")

    # Split data (ensure stratified split to maintain class balance)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)

    # Initialize TabNet
    tabnet_model = TabNetClassifier(**tabnet_params)

    # Train the model
    tabnet_model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        eval_metric=['accuracy'],
        patience=10,
        max_epochs=50,
        batch_size=1024,
        virtual_batch_size=128,
        num_workers=0,
        drop_last=False
    )

    # Evaluate the model
    y_pred = tabnet_model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results.append(accuracy)

    # Store classification report
    target_names = [str(cls) for cls in label_encoder.classes_]
    classification_reports[seed] = classification_report(y_test, y_pred, target_names=target_names)
    print(f"Random Seed: {seed}, Accuracy: {accuracy}")

# Analyze results
results_df = pd.DataFrame({
    'Random Seed': random_seeds,
    'Accuracy': results
})
results_summary = results_df['Accuracy'].describe()
results_summary['range'] = results_df['Accuracy'].max() - results_df['Accuracy'].min()

# Display results
print("\nAccuracy Results for TabNet with Different Random Seeds:")
print(results_df)

print("\nSummary Statistics:")
print(results_summary)

# Display classification reports
for seed, report in classification_reports.items():
    print(f"\nClassification Report for Seed {seed}:\n")
    print(report)







